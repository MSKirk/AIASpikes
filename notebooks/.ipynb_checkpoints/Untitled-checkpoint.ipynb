{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fitsio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_array(arr):\n",
    "    # Reshape to 1D without hard copy\n",
    "    # arr_1d = arr.ravel()\n",
    "    # Make a count of only the existing numbers (faster than histogram)\n",
    "    u, c = np.unique(arr, return_counts=True)\n",
    "    # Keep only rows that have values unique between rows\n",
    "    b = np.isin(arr, u[c==1]).all(axis=1)\n",
    "    return arr[b, :]\n",
    "\n",
    "\n",
    "def count_intersect(widx, raw_spikes, coincidental_1d_coords, count_filter_idx, counts):\n",
    "    \"\"\" Provides the coincidental coordinates and their indices in the raw spike file and occurence count\n",
    "    within the group. The indices in the raw spike file are used to retrieve the intensity values (before/after)\n",
    "\n",
    "    :param raw_spikes: list of spikes for one wavelength\n",
    "    :param coincidental_1d_coords: list of 1D coordinates of coincidental spikes integrated for the whole group\n",
    "    :param count_filter_idx: list of indices of the coincidental spikes mapping to the original list of spikes coords.\n",
    "    :param counts: distribution of spikes coords\n",
    "    :return: Coincidental coordinates, index in spike file, number of occurences >=n_co_spikes\n",
    "    \"\"\"\n",
    "\n",
    "    file_coords, idx1, idx2 = np.intersect1d(raw_spikes[0, :], coincidental_1d_coords, return_indices=True)\n",
    "    # Get intensity values at the coincidental coordinates\n",
    "    int_before = raw_spikes[1, idx1]\n",
    "    int_after = raw_spikes[2, idx1]\n",
    "    # Retrieve how many coincidental hits we had within the 8 neighbours.\n",
    "    group_counts = counts[count_filter_idx[idx2]]\n",
    "    # Map of the wavelength index, instead of actual wavelength value as 7-element group is 12s-time-based, not wavelength-based\n",
    "    widx = [widx]*len(file_coords)\n",
    "    \n",
    "    return file_coords, idx1, group_counts, widx, int_before, int_after\n",
    "\n",
    "\n",
    "def breakdown_coincidentals(spikes_list, coincidental_1d_coords, count_filter_idx, counts):\n",
    "    \"\"\" Provides the coincidental coordinates and their indices in the raw spike file and occurence count\n",
    "    within the group. The indices in the raw spike file are used to retrieve the intensity values (before/after)\n",
    "\n",
    "    :param raw_spikes: list of spikes for one wavelength\n",
    "    :param coincidental_1d_coords: list of 1D coordinates of coincidental spikes integrated for the whole group\n",
    "    :param count_filter_idx: list of indices of the coincidental spikes mapping to the original list of spikes coords.\n",
    "    :param counts: distribution of spikes coords\n",
    "    :return: Coincidental coordinates, index in spike file, number of occurences >=n_co_spikes\n",
    "    \"\"\"\n",
    "    \n",
    "    data_dict = {'coords':[], 'int1': [], 'int2': [], 'counts': [], 'widx': []}\n",
    "    \n",
    "    for widx, raw_spikes in enumerate(spikes_list):\n",
    "        file_coords, idx1, idx2 = np.intersect1d(raw_spikes[0, :], coincidental_1d_coords, return_indices=True)\n",
    "        # Get intensity values at the coincidental coordinates\n",
    "        #data = [raw_spikes[1, idx1], raw_spikes[2, idx1], counts[count_filter_idx[idx2]], [widx]*len(file_coords)]\n",
    "        # Map of the wavelength index, instead of actual wavelength value as 7-element group is 12s-time-based, not wavelength-based\n",
    "        data_dict['coords'].extend(file_coords)\n",
    "        data_dict['int1'].extend(raw_spikes[1, idx1])\n",
    "        data_dict['int2'].extend(raw_spikes[2, idx1])\n",
    "        data_dict['counts'].extend(counts[count_filter_idx[idx2]])\n",
    "        data_dict['widx'].extend([widx]*len(file_coords))\n",
    "        \n",
    "    \n",
    "    return data_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.environ['SPIKESDATA']\n",
    "spikes_db = pd.read_parquet(os.path.join(data_dir, 'spikes_df_2010.parquet'), engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Size</th>\n",
       "      <th>Wavelength</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GroupNumber</th>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">0</th>\n",
       "      <th>2010-05-13 00:00:02.090000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:02.09Z_0193.spikes...</td>\n",
       "      <td>106560</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-13 00:00:03.570000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:03.57Z_0094.spikes...</td>\n",
       "      <td>103680</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-13 00:00:05.070000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:05.07Z_0335.spikes...</td>\n",
       "      <td>126720</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-13 00:00:06.580000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:06.58Z_0171.spikes...</td>\n",
       "      <td>40320</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-13 00:00:08.080000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:08.08Z_0211.spikes...</td>\n",
       "      <td>60480</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-13 00:00:09.580000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:09.58Z_0304.spikes...</td>\n",
       "      <td>106560</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-13 00:00:11.080000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:11.08Z_0131.spikes...</td>\n",
       "      <td>100800</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">1</th>\n",
       "      <th>2010-05-13 00:00:14.080000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:14.08Z_0193.spikes...</td>\n",
       "      <td>43200</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-13 00:00:15.580000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:15.58Z_0094.spikes...</td>\n",
       "      <td>100800</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-13 00:00:17.080000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:17.08Z_0335.spikes...</td>\n",
       "      <td>126720</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-13 00:00:18.580000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:18.58Z_0171.spikes...</td>\n",
       "      <td>40320</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-13 00:00:20.090000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:20.09Z_0211.spikes...</td>\n",
       "      <td>60480</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-13 00:00:21.580000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:21.58Z_0304.spikes...</td>\n",
       "      <td>106560</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-13 00:00:23.070000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:23.07Z_0131.spikes...</td>\n",
       "      <td>100800</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                           Path  \\\n",
       "GroupNumber Time                                                                                  \n",
       "0           2010-05-13 00:00:02.090000+00:00  2010/05/13/2010-05-13T00:00:02.09Z_0193.spikes...   \n",
       "            2010-05-13 00:00:03.570000+00:00  2010/05/13/2010-05-13T00:00:03.57Z_0094.spikes...   \n",
       "            2010-05-13 00:00:05.070000+00:00  2010/05/13/2010-05-13T00:00:05.07Z_0335.spikes...   \n",
       "            2010-05-13 00:00:06.580000+00:00  2010/05/13/2010-05-13T00:00:06.58Z_0171.spikes...   \n",
       "            2010-05-13 00:00:08.080000+00:00  2010/05/13/2010-05-13T00:00:08.08Z_0211.spikes...   \n",
       "            2010-05-13 00:00:09.580000+00:00  2010/05/13/2010-05-13T00:00:09.58Z_0304.spikes...   \n",
       "            2010-05-13 00:00:11.080000+00:00  2010/05/13/2010-05-13T00:00:11.08Z_0131.spikes...   \n",
       "1           2010-05-13 00:00:14.080000+00:00  2010/05/13/2010-05-13T00:00:14.08Z_0193.spikes...   \n",
       "            2010-05-13 00:00:15.580000+00:00  2010/05/13/2010-05-13T00:00:15.58Z_0094.spikes...   \n",
       "            2010-05-13 00:00:17.080000+00:00  2010/05/13/2010-05-13T00:00:17.08Z_0335.spikes...   \n",
       "            2010-05-13 00:00:18.580000+00:00  2010/05/13/2010-05-13T00:00:18.58Z_0171.spikes...   \n",
       "            2010-05-13 00:00:20.090000+00:00  2010/05/13/2010-05-13T00:00:20.09Z_0211.spikes...   \n",
       "            2010-05-13 00:00:21.580000+00:00  2010/05/13/2010-05-13T00:00:21.58Z_0304.spikes...   \n",
       "            2010-05-13 00:00:23.070000+00:00  2010/05/13/2010-05-13T00:00:23.07Z_0131.spikes...   \n",
       "\n",
       "                                                Size  Wavelength  \n",
       "GroupNumber Time                                                  \n",
       "0           2010-05-13 00:00:02.090000+00:00  106560         193  \n",
       "            2010-05-13 00:00:03.570000+00:00  103680          94  \n",
       "            2010-05-13 00:00:05.070000+00:00  126720         335  \n",
       "            2010-05-13 00:00:06.580000+00:00   40320         171  \n",
       "            2010-05-13 00:00:08.080000+00:00   60480         211  \n",
       "            2010-05-13 00:00:09.580000+00:00  106560         304  \n",
       "            2010-05-13 00:00:11.080000+00:00  100800         131  \n",
       "1           2010-05-13 00:00:14.080000+00:00   43200         193  \n",
       "            2010-05-13 00:00:15.580000+00:00  100800          94  \n",
       "            2010-05-13 00:00:17.080000+00:00  126720         335  \n",
       "            2010-05-13 00:00:18.580000+00:00   40320         171  \n",
       "            2010-05-13 00:00:20.090000+00:00   60480         211  \n",
       "            2010-05-13 00:00:21.580000+00:00  106560         304  \n",
       "            2010-05-13 00:00:23.070000+00:00  100800         131  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spikes_db2 = spikes_db.set_index(['GroupNumber', 'Time'])\n",
    "spikes_db2.head(14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the filepaths (typically 7) for a given group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16777216, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################################################################\n",
    "# Pre-compute the 8-connectivity lookup table. This will be shared across parallel workers.\n",
    "################################################################################################\n",
    "# List of relative 2D coordinates for 8-neighbour connectiviy (9-element list). 1st one is the origin pixel.\n",
    "coords_8nb = np.array([[0, 0], [-1, 0], [-1, -1], [0, -1], [1, -1], [1, 0], [1, 1], [0, 1], [-1, 1]])\n",
    "# Array of 2D coordinates for a 4096 x 4096 array. Matrix convention is kept. [rows, cols] = [y-axis, x-axis]\n",
    "ny, nx = [4096, 4096]\n",
    "coords_1d = np.arange(nx * ny)\n",
    "coordy, coordx = np.unravel_index(coords_1d, [ny, nx]) # also possible by raveling a meshgrid() output\n",
    "coords2d = np.array([coordy, coordx])\n",
    "# Create the array of 2D coordinates of 8-neighbours associated with each pixel.\n",
    "# pixel 0 has 8 neighbour + itself, pixel 1 has 8 neighbour + itself, etc...\n",
    "coords2d_8nb = coords2d[np.newaxis, ...] + coords_8nb[..., np.newaxis]\n",
    "# Handle off-edges coordinates by clipping to the edges, operation done in-place. Here, square detector assumed. Update\n",
    "# to per-axis clipping if that ever changes for another instrument.\n",
    "np.clip(coords2d_8nb, 0, nx-1, out=coords2d_8nb)\n",
    "# Convert to 1D coordinates.\n",
    "index_8nb = np.array([coords2d_8nb[i, 0, :] * nx + coords2d_8nb[i, 1, :] for i in range(len(coords_8nb))],\n",
    "                     dtype='int32', order='C').T\n",
    "index_8nb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 8486)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_co_spikes = 2\n",
    "\n",
    "group_n = 0\n",
    "fpaths = spikes_db2.loc[group_n]['Path'].values\n",
    "spikes_list = [fitsio.read(os.path.join(data_dir, f)) for f in fpaths]\n",
    "print(len(spikes_list))\n",
    "spikes_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2908, 9)\n",
      "(31609, 9)\n"
     ]
    }
   ],
   "source": [
    "filter_arrays = [filter_array(index_8nb[raw_spikes[0, :], :]) for raw_spikes in spikes_list]\n",
    "group_array = np.concatenate(filter_arrays)\n",
    "print(filter_arrays[0].shape)\n",
    "print(spikes_arrays.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a curated distribution (numbers that do not exist aren't covered by the algorithm => faster than histogram)\n",
    "(distrib_values, counts) = np.unique(group_array, return_counts=True) # 35 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the indices of the coordinates that get hit more than n_co_spikes times\n",
    "coincidental_1d_coords = distrib_values[counts >= n_co_spikes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    9362     5266     5265 ...    13459     9363     5267]\n",
      " [    9706     5610     5609 ...    13803     9707     5611]\n",
      " [   10170     6074     6073 ...    14267    10171     6075]\n",
      " ...\n",
      " [16753554 16749458 16749457 ... 16757651 16753555 16749459]\n",
      " [16767005 16762909 16762908 ... 16771102 16767006 16762910]\n",
      " [16767143 16763047 16763046 ... 16771240 16767144 16763048]]\n",
      "(2908, 9)\n",
      "[False False False ... False False False]\n",
      "(2908,)\n"
     ]
    }
   ],
   "source": [
    "# Look at whether these coordinates are present in each of the 7 arrays\n",
    "filter_nb_spikes = filter_arrays[0]\n",
    "print(filter_nb_spikes)\n",
    "print(filter_nb_spikes.shape)\n",
    "\n",
    "co_spikes_rows = np.isin(filter_nb_spikes, coincidental_1d_coords).any(axis=1)\n",
    "print(co_spikes_rows)\n",
    "print(co_spikes_rows.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spikes_list[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "raw_spikes = spikes_list[0][0,:]\n",
    "nb_spikes = index_8nb[raw_spikes, :]\n",
    "nb_spikes.shape\n",
    "\n",
    "\n",
    "spikes_lists = [spikes_list[i+1:] for i in range(6)]\n",
    "for l in spikes_lists:\n",
    "    print(len(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30356,)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spikes_pix = [[spikes[0,:] for spikes in spikes_list[i+1:]] for i in range(6)]\n",
    "\n",
    "spikes_pix[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30356,)\n",
      "(36549,)\n",
      "(7993,)\n",
      "(13781,)\n",
      "(26443,)\n",
      "(27576,)\n"
     ]
    }
   ],
   "source": [
    "# For 1st wavelength\n",
    "co_mask = []\n",
    "for pixels in spikes_pix[0]:\n",
    "    print(pixels.shape)\n",
    "    mask = np.isin(index_8nb[pixels, :], index_8nb[spikes_list[0][0, :], :]).any(axis=1)\n",
    "    \n",
    "\n",
    "# co_mask_1 = np.isin(index_8nb[spikes_pix[1], :], index_8nb[spikes_list[1][0, :]]).any(axis=1)\n",
    "# co_mask_2 = np.isin(index_8nb[spikes_pix[2], :], index_8nb[spikes_list[2][0, :]]).any(axis=1)\n",
    "# co_mask_3 = np.isin(index_8nb[spikes_pix[3], :], index_8nb[spikes_list[3][0, :]]).any(axis=1)\n",
    "# co_mask_4 = np.isin(index_8nb[spikes_pix[4], :], index_8nb[spikes_list[4][0, :]]).any(axis=1)\n",
    "# co_mask_5 = np.isin(index_8nb[spikes_pix[5], :], index_8nb[spikes_list[5][0, :]]).any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coords</th>\n",
       "      <th>int1</th>\n",
       "      <th>int2</th>\n",
       "      <th>w1</th>\n",
       "      <th>w2</th>\n",
       "      <th>w3</th>\n",
       "      <th>w4</th>\n",
       "      <th>w5</th>\n",
       "      <th>w6</th>\n",
       "      <th>w7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [coords, int1, int2, w1, w2, w3, w4, w5, w6, w7]\n",
       "Index: []"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = ['coords' , 'int1', 'int2', 'w1', 'w2', 'w3', 'w4', 'w5', 'w6', 'w7']\n",
    "#column_names_list = [[names for names in column_names[:i]+column_names[i+1:]] for i in range(7)]\n",
    "\n",
    "df = pd.DataFrame(columns=column_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['w2', 'w3', 'w4', 'w5', 'w6', 'w7']\n",
      "['w1', 'w3', 'w4', 'w5', 'w6', 'w7']\n",
      "['w1', 'w2', 'w4', 'w5', 'w6', 'w7']\n",
      "['w1', 'w2', 'w3', 'w5', 'w6', 'w7']\n",
      "['w1', 'w2', 'w3', 'w4', 'w6', 'w7']\n",
      "['w1', 'w2', 'w3', 'w4', 'w5', 'w7']\n",
      "['w1', 'w2', 'w3', 'w4', 'w5', 'w6']\n"
     ]
    }
   ],
   "source": [
    "spikes_pix = [[spikes[0,:] for spikes in spikes_list[:i]+spikes_list[i+1:]] for i in range(7)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 1117)\n",
      "   coords  w1  w2  w3  w4  w5  w6  w7\n",
      "0   18917   1   1   0   0   0   0   0\n",
      "1   19192   0   1   0   1   0   0   0\n",
      "2   23013   1   1   0   0   0   0   0\n",
      "3   23287   0   1   0   1   0   0   0\n",
      "4   27109   1   1   0   0   0   0   0\n"
     ]
    }
   ],
   "source": [
    "# For 1st wavelength ~112 ms (%%timeit)\n",
    "\n",
    "pixels_ws = [spikes_list[i][0,:] for i in range(7)]\n",
    "nb_pixels_w1 = index_8nb[pixels_ws[0], :]\n",
    "# print(len(nb_pixels_w1))\n",
    "\n",
    "mask_w2_in_w1 = np.isin(nb_pixels_w1, index_8nb[pixels_ws[1], :]).any(axis=1)\n",
    "mask_w3_in_w1 = np.isin(nb_pixels_w1, index_8nb[pixels_ws[2], :]).any(axis=1)\n",
    "# mask_w4_in_w1 = np.isin(nb_pixels_w1, index_8nb[pixels_ws[3], :]).any(axis=1)\n",
    "# mask_w5_in_w1 = np.isin(nb_pixels_w1, index_8nb[pixels_ws[4], :]).any(axis=1)\n",
    "# mask_w6_in_w1 = np.isin(nb_pixels_w1, index_8nb[pixels_ws[5], :]).any(axis=1)\n",
    "# mask_w7_in_w1 = np.isin(nb_pixels_w1, index_8nb[pixels_ws[6], :]).any(axis=1)\n",
    "\n",
    "masks_w1 = [np.isin(nb_pixels_w1, index_8nb[pixels, :]).any(axis=1) for pixels in spikes_pix[0]]\n",
    "mask_w1_arr = np.array(masks_w1)\n",
    "select_pixels = mask_w1_arr.any(axis=0)\n",
    "coords_w1 =pixels_ws[0][select_pixels] # Combine the mask to fetch everything in one go, using broadcasting??\n",
    "w1tables = np.insert(mask_w1_arr[:, select_pixels], 1, True, axis=0)\n",
    "w1_arr = np.concatenate([coords_w1[np.newaxis,...], w1tables], axis=0)\n",
    "print(w1_arr.shape)\n",
    "\n",
    "df1 = pd.DataFrame(w1_arr.T, columns=['coords', 'w1', 'w2', 'w3', 'w4', 'w5', 'w6', 'w7'])\n",
    "print(df1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 3177)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: coords, dtype: object)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For 2nd wavelength\n",
    "\n",
    "reduction_mask = np.isin(pixels_ws[1], coords_w1, invert=True)\n",
    "pixels_w2_new = pixels_ws[1][reduction_mask]\n",
    "\n",
    "nb_pixels_w2 = index_8nb[pixels_w2_new, :]\n",
    "\n",
    "masks_w2 = [np.isin(nb_pixels_w2, index_8nb[pixels, :]).any(axis=1) for pixels in spikes_pix[1]]\n",
    "mask_w2_arr = np.array(masks_w2)\n",
    "select_pixels = mask_w2_arr.any(axis=0)\n",
    "coords_w2 =pixels_w2_new[select_pixels] # Combine the mask to fetch everything in one go, using broadcasting??\n",
    "w2tables = np.insert(mask_w2_arr[:, select_pixels], 1, True, axis=0)\n",
    "\n",
    "w2_arr = np.concatenate([coords_w2[np.newaxis,...], w2tables], axis=0)\n",
    "print(w2_arr.shape)\n",
    "w12 = np.concatenate([w1_arr, w2_arr], axis=1)\n",
    "#print(w12.shape)\n",
    "\n",
    "#print(mask_w2_arr2)\n",
    "\n",
    "df['coords']\n",
    "                   \n",
    "                   \n",
    "# # Retrieve intensity values for the selected coordinates\n",
    "# intensity1 = spikes_list[1][1,reduction_mask][select_pixels]\n",
    "# intensity2 = spikes_list[1][2,reduction_mask][select_pixels]\n",
    "\n",
    "# #datadict = {'coords':coords_w2, 'w1':wtables[0], 'w2':wtables[1], 'w3':wtables[2], 'w4':wtables[3], 'w5':wtables[4], 'w6':wtables[5], 'w7':wtables[6]}\n",
    "\n",
    "# df2 = pd.DataFrame(w2_arr.T, columns=['coords', 'w1', 'w2', 'w3', 'w4', 'w5', 'w6', 'w7'])\n",
    "# print(df2.head())\n",
    "\n",
    "# df2b = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15,)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(10)\n",
    "b = np.arange(5)\n",
    "c = np.concatenate([a,b])\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   coords  w1  w2  w3  w4  w5  w6  w7\n",
      "0   18917   1   1   0   0   0   0   0\n",
      "1   19192   1   0   0   1   0   0   0\n",
      "2   23013   1   1   0   0   0   0   0\n",
      "3   23287   1   0   0   1   0   0   0\n",
      "4   27109   1   1   0   0   0   0   0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 2]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,4,2,7,90]\n",
    "a[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
