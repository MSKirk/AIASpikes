{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fitsio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_coincidentals(spikes_list, idx):\n",
    "    \n",
    "    # Spikes coordinates at given wavelength index\n",
    "    spikes_w = spikes_list[idx]\n",
    "    # Associated neighbour coordinates\n",
    "    nb_pixels = index_8nb[spikes_w[0, :], :]\n",
    "    # Sublist of spikes data that will excludes the one serving as template\n",
    "    spikes_sublist = spikes_list[:idx]+spikes_list[idx+1:]\n",
    "    # Coincidental cross-referencing. \n",
    "    mask_w_arr = np.array([np.isin(nb_pixels, index_8nb[spikes[0,:], :]).any(axis=1) for spikes in spikes_sublist])\n",
    "    select_pixels = mask_w_arr.any(axis=0)\n",
    "    coords_w = spikes_w[0, select_pixels] \n",
    "    w_tables = np.insert(mask_w_arr[:, select_pixels], idx, True, axis=0)\n",
    "    # Retrieve intensity values for the selected coordinates\n",
    "    intensities = spikes_w[ 1:, select_pixels]\n",
    "    arr_w = np.concatenate([coords_w[np.newaxis,...], intensities, w_tables], axis=0)\n",
    "    arr_w = np.insert(arr_w, 3, idx, axis=0)\n",
    "    \n",
    "    return arr_w\n",
    "\n",
    "def extract_all_coincidentals(spikes_list):\n",
    "    # column_names = ['coords' , 'int1', 'int2', 'wref', 'w0', 'w1', 'w2', 'w3', 'w4', 'w5', 'w6']\n",
    "    group_data = np.concatenate([extract_coincidentals(spikes_list, i) for i in range(7)], axis=1).T\n",
    "    #coincidental_spikes_df = pd.DataFrame(group_data.T, columns=column_names)\n",
    "    return group_data\n",
    "\n",
    "def read_group(files):\n",
    "    return [fitsio.read(os.path.join(data_dir, f)) for f in files]\n",
    "\n",
    "\n",
    "def process_group(fpaths):\n",
    "    spikes_list = [fitsio.read(os.path.join(data_dir, f)) for f in fpaths]\n",
    "    group_data = np.concatenate([extract_coincidentals(spikes_list, i) for i in range(7)], axis=1).T\n",
    "    return group_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GroupNumber  Time                            \n",
       "0            2010-05-13 00:00:02.090000+00:00    2010/05/13/2010-05-13T00:00:02.09Z_0193.spikes...\n",
       "             2010-05-13 00:00:03.570000+00:00    2010/05/13/2010-05-13T00:00:03.57Z_0094.spikes...\n",
       "             2010-05-13 00:00:05.070000+00:00    2010/05/13/2010-05-13T00:00:05.07Z_0335.spikes...\n",
       "             2010-05-13 00:00:06.580000+00:00    2010/05/13/2010-05-13T00:00:06.58Z_0171.spikes...\n",
       "             2010-05-13 00:00:08.080000+00:00    2010/05/13/2010-05-13T00:00:08.08Z_0211.spikes...\n",
       "Name: Path, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = os.environ['SPIKESDATA']\n",
    "spikes_df = pd.read_parquet(os.path.join(data_dir, 'spikes_df_2010.parquet'), engine='pyarrow')\n",
    "spikes_df2 = spikes_df.set_index(['GroupNumber', 'Time'])\n",
    "path_Series = spikes_df2['Path']\n",
    "path_Series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tintervals = pd.interval_range(start=spikes_df['Time'].iloc[0], end=spikes_df['Time'].iloc[-1], freq='10D', closed='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     1,     2, ..., 71998, 71999, 72000])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tselect = (spikes_df['Time'] >= tintervals[0].left) & (spikes_df['Time'] < tintervals[0].right)\n",
    "groups = spikes_df['GroupNumber'].loc[tselect].unique()\n",
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GroupNumber  Time                            \n",
       "0            2010-05-13 00:00:02.090000+00:00    2010/05/13/2010-05-13T00:00:02.09Z_0193.spikes...\n",
       "             2010-05-13 00:00:03.570000+00:00    2010/05/13/2010-05-13T00:00:03.57Z_0094.spikes...\n",
       "             2010-05-13 00:00:05.070000+00:00    2010/05/13/2010-05-13T00:00:05.07Z_0335.spikes...\n",
       "             2010-05-13 00:00:06.580000+00:00    2010/05/13/2010-05-13T00:00:06.58Z_0171.spikes...\n",
       "             2010-05-13 00:00:08.080000+00:00    2010/05/13/2010-05-13T00:00:08.08Z_0211.spikes...\n",
       "             2010-05-13 00:00:09.580000+00:00    2010/05/13/2010-05-13T00:00:09.58Z_0304.spikes...\n",
       "             2010-05-13 00:00:11.080000+00:00    2010/05/13/2010-05-13T00:00:11.08Z_0131.spikes...\n",
       "1            2010-05-13 00:00:14.080000+00:00    2010/05/13/2010-05-13T00:00:14.08Z_0193.spikes...\n",
       "             2010-05-13 00:00:15.580000+00:00    2010/05/13/2010-05-13T00:00:15.58Z_0094.spikes...\n",
       "             2010-05-13 00:00:17.080000+00:00    2010/05/13/2010-05-13T00:00:17.08Z_0335.spikes...\n",
       "             2010-05-13 00:00:18.580000+00:00    2010/05/13/2010-05-13T00:00:18.58Z_0171.spikes...\n",
       "             2010-05-13 00:00:20.090000+00:00    2010/05/13/2010-05-13T00:00:20.09Z_0211.spikes...\n",
       "             2010-05-13 00:00:21.580000+00:00    2010/05/13/2010-05-13T00:00:21.58Z_0304.spikes...\n",
       "             2010-05-13 00:00:23.070000+00:00    2010/05/13/2010-05-13T00:00:23.07Z_0131.spikes...\n",
       "2            2010-05-13 00:00:26.080000+00:00    2010/05/13/2010-05-13T00:00:26.08Z_0193.spikes...\n",
       "             2010-05-13 00:00:27.580000+00:00    2010/05/13/2010-05-13T00:00:27.58Z_0094.spikes...\n",
       "             2010-05-13 00:00:29.080000+00:00    2010/05/13/2010-05-13T00:00:29.08Z_0335.spikes...\n",
       "             2010-05-13 00:00:30.580000+00:00    2010/05/13/2010-05-13T00:00:30.58Z_0171.spikes...\n",
       "             2010-05-13 00:00:32.080000+00:00    2010/05/13/2010-05-13T00:00:32.08Z_0211.spikes...\n",
       "             2010-05-13 00:00:33.580000+00:00    2010/05/13/2010-05-13T00:00:33.58Z_0304.spikes...\n",
       "             2010-05-13 00:00:35.080000+00:00    2010/05/13/2010-05-13T00:00:35.08Z_0131.spikes...\n",
       "Name: Path, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spikes_df2['Path'].loc[groups[0:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16777216, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################################################################\n",
    "# Pre-compute the 8-connectivity lookup table. This will be shared across parallel workers.\n",
    "################################################################################################\n",
    "# List of relative 2D coordinates for 8-neighbour connectiviy (9-element list). 1st one is the origin pixel.\n",
    "coords_8nb = np.array([[0, 0], [-1, 0], [-1, -1], [0, -1], [1, -1], [1, 0], [1, 1], [0, 1], [-1, 1]])\n",
    "# Array of 2D coordinates for a 4096 x 4096 array. Matrix convention is kept. [rows, cols] = [y-axis, x-axis]\n",
    "ny, nx = [4096, 4096]\n",
    "coords_1d = np.arange(nx * ny)\n",
    "coordy, coordx = np.unravel_index(coords_1d, [ny, nx]) # also possible by raveling a meshgrid() output\n",
    "coords2d = np.array([coordy, coordx])\n",
    "# Create the array of 2D coordinates of 8-neighbours associated with each pixel.\n",
    "# pixel 0 has 8 neighbour + itself, pixel 1 has 8 neighbour + itself, etc...\n",
    "coords2d_8nb = coords2d[np.newaxis, ...] + coords_8nb[..., np.newaxis]\n",
    "# Handle off-edges coordinates by clipping to the edges, operation done in-place. Here, square detector assumed. Update\n",
    "# to per-axis clipping if that ever changes for another instrument.\n",
    "np.clip(coords2d_8nb, 0, nx-1, out=coords2d_8nb)\n",
    "# Convert to 1D coordinates.\n",
    "index_8nb = np.array([coords2d_8nb[i, 0, :] * nx + coords2d_8nb[i, 1, :] for i in range(len(coords_8nb))],\n",
    "                     dtype='int32', order='C').T\n",
    "index_8nb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = spikes_df2.index.get_level_values('GroupNumber').unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time\n",
       "2010-05-13 00:00:02.090000+00:00    2010/05/13/2010-05-13T00:00:02.09Z_0193.spikes...\n",
       "2010-05-13 00:00:03.570000+00:00    2010/05/13/2010-05-13T00:00:03.57Z_0094.spikes...\n",
       "2010-05-13 00:00:05.070000+00:00    2010/05/13/2010-05-13T00:00:05.07Z_0335.spikes...\n",
       "2010-05-13 00:00:06.580000+00:00    2010/05/13/2010-05-13T00:00:06.58Z_0171.spikes...\n",
       "2010-05-13 00:00:08.080000+00:00    2010/05/13/2010-05-13T00:00:08.08Z_0211.spikes...\n",
       "2010-05-13 00:00:09.580000+00:00    2010/05/13/2010-05-13T00:00:09.58Z_0304.spikes...\n",
       "2010-05-13 00:00:11.080000+00:00    2010/05/13/2010-05-13T00:00:11.08Z_0131.spikes...\n",
       "Name: Path, dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths_list_groups = [path_Series.loc[group_n] for group_n in groups[0:100]]\n",
    "paths_list_groups[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.61 ms ± 21.5 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit data = read_group(paths_list_groups[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.88 s, sys: 922 ms, total: 7.8 s\n",
      "Wall time: 6.94 s\n"
     ]
    }
   ],
   "source": [
    "%time spikes_groups = [read_group(files) for files in paths_list_groups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:35035</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:35819/status' target='_blank'>http://127.0.0.1:35819/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>33.27 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:35035' processes=4 threads=4, memory=33.27 GB>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster = LocalCluster(n_workers=4, threads_per_worker=1)\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.bag as db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_files = db.from_sequence(paths_list_groups, npartitions=10)\n",
    "res = bag_files.map(read_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.69 s, sys: 3.47 s, total: 6.16 s\n",
      "Wall time: 7.95 s\n"
     ]
    }
   ],
   "source": [
    "%time res = bag_files.map(read_group).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time data_groups = [extract_all_coincidentals(spikes_list) for spikes_list in spikes_groups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delayed_spikes = [delayed(extract_all_coincidentals)(spikes_list) for spikes_list in spikes_groups] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
