{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fitsio\n",
    "from pathlib import Path, PurePath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lookup_8nb(nx, ny):\n",
    "    \"\"\" Pre-compute the 8-connectivity lookup table. This will be shared across parallel workers.\n",
    "    :param nx:\n",
    "    :param ny:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # List of relative 2D coordinates for 8-neighbour connectiviy (9-element list). 1st one is the origin pixel.\n",
    "    coords_8nb = np.array([[0, 0], [-1, 0], [-1, -1], [0, -1], [1, -1], [1, 0], [1, 1], [0, 1], [-1, 1]])\n",
    "    # Array of 2D coordinates for a 4096 x 4096 array. Matrix convention is kept. [rows, cols] = [y-axis, x-axis]\n",
    "    coords_1d = np.arange(nx * ny)\n",
    "    coordy, coordx = np.unravel_index(coords_1d, [ny, nx]) # also possible by raveling a meshgrid() output\n",
    "    coords2d = np.array([coordy, coordx])\n",
    "    # Create the array of 2D coordinates of 8-neighbours associated with each pixel.\n",
    "    # pixel 0 has 8 neighbour + itself, pixel 1 has 8 neighbour + itself, etc...\n",
    "    coords2d_8nb = coords2d[np.newaxis, ...] + coords_8nb[..., np.newaxis]\n",
    "    # Handle off-edges coordinates by clipping to the edges, operation done in-place. Here, square detector assumed.\n",
    "    # to per-axis clipping if that ever changes for another instrument.\n",
    "    np.clip(coords2d_8nb, 0, nx-1, out=coords2d_8nb)\n",
    "    # Convert to 1D coordinates.\n",
    "    lookup_coords = np.array([coords2d_8nb[i, 0, :] * nx + coords2d_8nb[i, 1, :] for i in range(len(coords_8nb))],\n",
    "                         dtype='int32', order='C').T\n",
    "    return lookup_coords\n",
    "\n",
    "\n",
    "def extract_coincidentals(spikes_list, idx):\n",
    "    # Spikes coordinates at given wavelength index\n",
    "    spikes_w = spikes_list[idx]\n",
    "    # Associated neighbour coordinates\n",
    "    nb_pixels = index_8nb[spikes_w[0, :], :]\n",
    "    # Sublist of spikes data that will excludes the one serving as template\n",
    "    spikes_sublist = spikes_list[:idx] + spikes_list[idx + 1:]\n",
    "    # Coincidental cross-referencing.\n",
    "    mask_w_arr = np.array([np.isin(nb_pixels, index_8nb[spikes[0, :], :]).any(axis=1) for spikes in spikes_sublist])\n",
    "    select_pixels = mask_w_arr.any(axis=0)\n",
    "    coords_w = spikes_w[0, select_pixels]\n",
    "    w_tables = np.insert(mask_w_arr[:, select_pixels], idx, True, axis=0)\n",
    "    # Retrieve intensity values for the selected coordinates\n",
    "    intensities = spikes_w[1:, select_pixels]\n",
    "    arr_w = np.concatenate([coords_w[np.newaxis, ...], intensities, w_tables], axis=0)\n",
    "    arr_w = np.insert(arr_w, 3, idx, axis=0)\n",
    "\n",
    "    return arr_w\n",
    "\n",
    "\n",
    "def process_group(group_n):\n",
    "    fpaths = path_Series.loc[group_n]\n",
    "    spikes_list = [fitsio.read(os.path.join(os.environ['SPIKESDATA'], f)) for f in fpaths]\n",
    "    group_data = np.concatenate([extract_coincidentals(spikes_list, i) for i in range(7)], axis=1)\n",
    "    column_names = ['coords', 'int1', 'int2', 'wref', 'w0', 'w1', 'w2', 'w3', 'w4', 'w5', 'w6']\n",
    "    coincidental_spikes_df = pd.DataFrame(group_data.T, columns=column_names)\n",
    "    coincidental_spikes_df['GroupNumber'] = group_n\n",
    "    return coincidental_spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdir = os.path.join(os.environ['SPIKESDATA'], 'parquet_dataframes')\n",
    "outputdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.environ['SPIKESDATA']\n",
    "spikes_df = pd.read_parquet(os.path.join(data_dir, 'spikes_df_2010.parquet'), engine='pyarrow')\n",
    "spikes_df2 = spikes_df.set_index(['GroupNumber', 'Time'])\n",
    "path_Series = spikes_df2['Path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_Series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes_df2.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_8nb = create_lookup_8nb(4096, 4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tinterval = pd.Interval(left=pd.Timestamp('2010-05-29 00:00:00', tz='UTC'), right=pd.Timestamp('2010-05-30 00:00:00', tz='UTC'))\n",
    "groups = spikes_df['GroupNumber'].loc[(spikes_df['Time'] >= tinterval.left) & (spikes_df['Time'] < tinterval.right)].unique()\n",
    "len(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes_df2.loc[groups[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool(processes=60) as pool:\n",
    "    group_df_list = pool.map(process_group, groups, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = pd.concat(group_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(group_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [len(gdf) for gdf in group_df_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tinterval2 = pd.Interval(left=pd.Timestamp('2010-05-27 00:00:00', tz='UTC'), right=pd.Timestamp('2010-05-28 04:00:00', tz='UTC'))\n",
    "groups2 = spikes_df['GroupNumber'].loc[(spikes_df['Time'] >= tinterval2.left) & (spikes_df['Time'] < tinterval2.right)].unique()\n",
    "len(groups2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes_df2.loc[groups2[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
