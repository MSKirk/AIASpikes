{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fitsio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_array(arr):\n",
    "    # Reshape to 1D without hard copy\n",
    "    arr_1d = arr.ravel()\n",
    "    # Make a count of only the existing numbers (faster than histogram)\n",
    "    u_elem, c = np.unique(arr_1d, return_counts=True)\n",
    "    # Get which elements are duplicates. \n",
    "    duplicates = u_elem[c > 1]\n",
    "    # Get the rows where these duplicates belongs\n",
    "    dup_idx = np.concatenate([np.where(arr_1d == d)[0] for d in duplicates])\n",
    "    dup_rows = np.unique(dup_idx // arr.shape[1])\n",
    "    # Remove the rows from the array\n",
    "    b = np.delete(arr, dup_rows, axis=0)\n",
    "\n",
    "    return b\n",
    "\n",
    "\n",
    "\n",
    "def count_intersect(widx, raw_spikes, coincidental_1d_coords, count_filter_idx, counts):\n",
    "    \"\"\" Provides the coincidental coordinates and their indices in the raw spike file and occurence count\n",
    "    within the group. The indices in the raw spike file are used to retrieve the intensity values (before/after)\n",
    "\n",
    "    :param raw_spikes: list of spikes for one wavelength\n",
    "    :param coincidental_1d_coords: list of 1D coordinates of coincidental spikes integrated for the whole group\n",
    "    :param count_filter_idx: list of indices of the coincidental spikes mapping to the original list of spikes coords.\n",
    "    :param counts: distribution of spikes coords\n",
    "    :return: Coincidental coordinates, index in spike file, number of occurences >=n_co_spikes\n",
    "    \"\"\"\n",
    "\n",
    "    file_coords, idx1, idx2 = np.intersect1d(raw_spikes[0, :], coincidental_1d_coords, return_indices=True)\n",
    "    # Get intensity values at the coincidental coordinates\n",
    "    int_before = raw_spikes[1, idx1]\n",
    "    int_after = raw_spikes[2, idx1]\n",
    "    # Retrieve how many coincidental hits we had within the 8 neighbours.\n",
    "    group_counts = counts[count_filter_idx[idx2]]\n",
    "    # Map of the wavelength index, instead of actual wavelength value as 7-element group is 12s-time-based, not wavelength-based\n",
    "    widx = [widx]*len(file_coords)\n",
    "    \n",
    "    return file_coords, idx1, group_counts, widx, int_before, int_after\n",
    "\n",
    "\n",
    "def breakdown_coincidentals(spikes_list, coincidental_1d_coords, count_filter_idx, counts):\n",
    "    \"\"\" Provides the coincidental coordinates and their indices in the raw spike file and occurence count\n",
    "    within the group. The indices in the raw spike file are used to retrieve the intensity values (before/after)\n",
    "\n",
    "    :param raw_spikes: list of spikes for one wavelength\n",
    "    :param coincidental_1d_coords: list of 1D coordinates of coincidental spikes integrated for the whole group\n",
    "    :param count_filter_idx: list of indices of the coincidental spikes mapping to the original list of spikes coords.\n",
    "    :param counts: distribution of spikes coords\n",
    "    :return: Coincidental coordinates, index in spike file, number of occurences >=n_co_spikes\n",
    "    \"\"\"\n",
    "    \n",
    "    data_dict = {'coords':[], 'int1': [], 'int2': [], 'counts': [], 'widx': []}\n",
    "    \n",
    "    for widx, raw_spikes in enumerate(spikes_list):\n",
    "        file_coords, idx1, idx2 = np.intersect1d(raw_spikes[0, :], coincidental_1d_coords, return_indices=True)\n",
    "        # Get intensity values at the coincidental coordinates\n",
    "        #data = [raw_spikes[1, idx1], raw_spikes[2, idx1], counts[count_filter_idx[idx2]], [widx]*len(file_coords)]\n",
    "        # Map of the wavelength index, instead of actual wavelength value as 7-element group is 12s-time-based, not wavelength-based\n",
    "        data_dict['coords'].extend(file_coords)\n",
    "        data_dict['int1'].extend(raw_spikes[1, idx1])\n",
    "        data_dict['int2'].extend(raw_spikes[2, idx1])\n",
    "        data_dict['counts'].extend(counts[count_filter_idx[idx2]])\n",
    "        data_dict['widx'].extend([widx]*len(file_coords))\n",
    "        \n",
    "    \n",
    "    return data_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.environ['SPIKESDATA']\n",
    "spikes_db = pd.read_parquet(os.path.join(data_dir, 'spikes_df_2010.parquet'), engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Size</th>\n",
       "      <th>Wavelength</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GroupNumber</th>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">0</th>\n",
       "      <th>2010-05-13 00:00:02.090000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:02.09Z_0193.spikes...</td>\n",
       "      <td>106560</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-13 00:00:03.570000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:03.57Z_0094.spikes...</td>\n",
       "      <td>103680</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-13 00:00:05.070000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:05.07Z_0335.spikes...</td>\n",
       "      <td>126720</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-13 00:00:06.580000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:06.58Z_0171.spikes...</td>\n",
       "      <td>40320</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-13 00:00:08.080000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:08.08Z_0211.spikes...</td>\n",
       "      <td>60480</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-13 00:00:09.580000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:09.58Z_0304.spikes...</td>\n",
       "      <td>106560</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-13 00:00:11.080000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:11.08Z_0131.spikes...</td>\n",
       "      <td>100800</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">1</th>\n",
       "      <th>2010-05-13 00:00:14.080000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:14.08Z_0193.spikes...</td>\n",
       "      <td>43200</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-13 00:00:15.580000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:15.58Z_0094.spikes...</td>\n",
       "      <td>100800</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-13 00:00:17.080000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:17.08Z_0335.spikes...</td>\n",
       "      <td>126720</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-13 00:00:18.580000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:18.58Z_0171.spikes...</td>\n",
       "      <td>40320</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-13 00:00:20.090000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:20.09Z_0211.spikes...</td>\n",
       "      <td>60480</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-13 00:00:21.580000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:21.58Z_0304.spikes...</td>\n",
       "      <td>106560</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-13 00:00:23.070000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:23.07Z_0131.spikes...</td>\n",
       "      <td>100800</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                           Path  \\\n",
       "GroupNumber Time                                                                                  \n",
       "0           2010-05-13 00:00:02.090000+00:00  2010/05/13/2010-05-13T00:00:02.09Z_0193.spikes...   \n",
       "            2010-05-13 00:00:03.570000+00:00  2010/05/13/2010-05-13T00:00:03.57Z_0094.spikes...   \n",
       "            2010-05-13 00:00:05.070000+00:00  2010/05/13/2010-05-13T00:00:05.07Z_0335.spikes...   \n",
       "            2010-05-13 00:00:06.580000+00:00  2010/05/13/2010-05-13T00:00:06.58Z_0171.spikes...   \n",
       "            2010-05-13 00:00:08.080000+00:00  2010/05/13/2010-05-13T00:00:08.08Z_0211.spikes...   \n",
       "            2010-05-13 00:00:09.580000+00:00  2010/05/13/2010-05-13T00:00:09.58Z_0304.spikes...   \n",
       "            2010-05-13 00:00:11.080000+00:00  2010/05/13/2010-05-13T00:00:11.08Z_0131.spikes...   \n",
       "1           2010-05-13 00:00:14.080000+00:00  2010/05/13/2010-05-13T00:00:14.08Z_0193.spikes...   \n",
       "            2010-05-13 00:00:15.580000+00:00  2010/05/13/2010-05-13T00:00:15.58Z_0094.spikes...   \n",
       "            2010-05-13 00:00:17.080000+00:00  2010/05/13/2010-05-13T00:00:17.08Z_0335.spikes...   \n",
       "            2010-05-13 00:00:18.580000+00:00  2010/05/13/2010-05-13T00:00:18.58Z_0171.spikes...   \n",
       "            2010-05-13 00:00:20.090000+00:00  2010/05/13/2010-05-13T00:00:20.09Z_0211.spikes...   \n",
       "            2010-05-13 00:00:21.580000+00:00  2010/05/13/2010-05-13T00:00:21.58Z_0304.spikes...   \n",
       "            2010-05-13 00:00:23.070000+00:00  2010/05/13/2010-05-13T00:00:23.07Z_0131.spikes...   \n",
       "\n",
       "                                                Size  Wavelength  \n",
       "GroupNumber Time                                                  \n",
       "0           2010-05-13 00:00:02.090000+00:00  106560         193  \n",
       "            2010-05-13 00:00:03.570000+00:00  103680          94  \n",
       "            2010-05-13 00:00:05.070000+00:00  126720         335  \n",
       "            2010-05-13 00:00:06.580000+00:00   40320         171  \n",
       "            2010-05-13 00:00:08.080000+00:00   60480         211  \n",
       "            2010-05-13 00:00:09.580000+00:00  106560         304  \n",
       "            2010-05-13 00:00:11.080000+00:00  100800         131  \n",
       "1           2010-05-13 00:00:14.080000+00:00   43200         193  \n",
       "            2010-05-13 00:00:15.580000+00:00  100800          94  \n",
       "            2010-05-13 00:00:17.080000+00:00  126720         335  \n",
       "            2010-05-13 00:00:18.580000+00:00   40320         171  \n",
       "            2010-05-13 00:00:20.090000+00:00   60480         211  \n",
       "            2010-05-13 00:00:21.580000+00:00  106560         304  \n",
       "            2010-05-13 00:00:23.070000+00:00  100800         131  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spikes_db2 = spikes_db.set_index(['GroupNumber', 'Time'])\n",
    "spikes_db2.head(14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the filepaths (typically 7) for a given group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16777216, 9)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################################################################\n",
    "# Pre-compute the 8-connectivity lookup table. This will be shared across parallel workers.\n",
    "################################################################################################\n",
    "# List of relative 2D coordinates for 8-neighbour connectiviy (9-element list). 1st one is the origin pixel.\n",
    "coords_8nb = np.array([[0, 0], [-1, 0], [-1, -1], [0, -1], [1, -1], [1, 0], [1, 1], [0, 1], [-1, 1]])\n",
    "# Array of 2D coordinates for a 4096 x 4096 array. Matrix convention is kept. [rows, cols] = [y-axis, x-axis]\n",
    "ny, nx = [4096, 4096]\n",
    "coords_1d = np.arange(nx * ny)\n",
    "coordy, coordx = np.unravel_index(coords_1d, [ny, nx]) # also possible by raveling a meshgrid() output\n",
    "coords2d = np.array([coordy, coordx])\n",
    "# Create the array of 2D coordinates of 8-neighbours associated with each pixel.\n",
    "# pixel 0 has 8 neighbour + itself, pixel 1 has 8 neighbour + itself, etc...\n",
    "coords2d_8nb = coords2d[np.newaxis, ...] + coords_8nb[..., np.newaxis]\n",
    "# Handle off-edges coordinates by clipping to the edges, operation done in-place. Here, square detector assumed. Update\n",
    "# to per-axis clipping if that ever changes for another instrument.\n",
    "np.clip(coords2d_8nb, 0, nx-1, out=coords2d_8nb)\n",
    "# Convert to 1D coordinates.\n",
    "index_8nb = np.array([coords2d_8nb[i, 0, :] * nx + coords2d_8nb[i, 1, :] for i in range(len(coords_8nb))],\n",
    "                     dtype='int32', order='C').T\n",
    "index_8nb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 8486)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_co_spikes = 2\n",
    "\n",
    "group_n = 0\n",
    "fpaths = spikes_db2.loc[group_n]['Path'].values\n",
    "spikes_list = [fitsio.read(os.path.join(data_dir, f)) for f in fpaths]\n",
    "spikes_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_spikes = spikes_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270 ms ± 1.53 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "b = filter_array(index_8nb2[raw_spikes[0, :], :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes_arrays = [filter_array(index_8nb[raw_spikes[0, :], :]) for raw_spikes in spikes_list]\n",
    "# spikes list: [7 files] x [1D coordinates, intensity before despiking replacement, intensity after despiking]\n",
    "u_spikes = np.array([spikes_nb.ravel() for spikes_nb in spikes_arrays])\n",
    "# Make a curated distribution (numbers that do not exist aren't covered by the algorithm => faster than histogram)\n",
    "(distrib_values, counts) = np.unique(u_spikes, return_counts=True) # 35 ms\n",
    "# Get the indices of the coordinates that get hit more than n_co_spikes times\n",
    "coincidental_1d_coords = distrib_values[counts >= n_co_spikes]\n",
    "\n",
    "# For each of the 7 files\n",
    "# Get these coincicental spikes coordinates\n",
    "coords, idx1, idx2 = np.intersect1d(u_spikes[0], coincidental_1d_coords, return_indices=True)\n",
    "# which rows in the neighbour array?\n",
    "rows = np.unique((idx1 / spikes_arrays[0].shape[1]).astype(int))\n",
    "select_spikes_coords = spikes_arrays[0][rows, 0]\n",
    "raw_spikes_idx = [np.where(spikes_list[0][0, :] == s) for s in select_spikes_coords]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
