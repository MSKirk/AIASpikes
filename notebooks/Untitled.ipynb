{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fitsio\n",
    "import cudf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_coincidentals(spikes_list, idx):\n",
    "    \n",
    "    # Spikes coordinates at given wavelength index\n",
    "    spikes_w = spikes_list[idx]\n",
    "    # Associated neighbour coordinates\n",
    "    nb_pixels = index_8nb[spikes_w[0, :], :]\n",
    "    # Sublist of spikes data that will excludes the one serving as template\n",
    "    spikes_sublist = spikes_list[:idx]+spikes_list[idx+1:]\n",
    "    # Coincidental cross-referencing. \n",
    "    mask_w_arr = np.array([np.isin(nb_pixels, index_8nb[spikes[0,:], :]).any(axis=1) for spikes in spikes_sublist])\n",
    "    select_pixels = mask_w_arr.any(axis=0)\n",
    "    coords_w = spikes_w[0, select_pixels] \n",
    "    w_tables = np.insert(mask_w_arr[:, select_pixels], idx, True, axis=0)\n",
    "    # Retrieve intensity values for the selected coordinates\n",
    "    intensities = spikes_w[1:, select_pixels]\n",
    "    arr_w = np.concatenate([coords_w[np.newaxis,...], intensities, w_tables], axis=0)\n",
    "    \n",
    "    return arr_w\n",
    "\n",
    "\n",
    "def cp_insert(a, b, idx, axis):\n",
    "    c = cp.concatenate([a[:idx,:], b, a[idx:]], axis=axis)\n",
    "    return c\n",
    "\n",
    "\n",
    "def gpu_extract_coincidentals(spikes_list, idx):\n",
    "    \n",
    "    # Spikes coordinates at given wavelength index\n",
    "    spikes_w = spikes_list[idx]\n",
    "    # Associated neighbour coordinates\n",
    "    nb_pixels = gindex_8nb[spikes_w[0, :], :]\n",
    "    # Sublist of spikes data that will excludes the one serving as template\n",
    "    spikes_sublist = spikes_list[:idx]+spikes_list[idx+1:]\n",
    "    # Coincidental cross-referencing. \n",
    "    mask_w_arr = cp.array([cp.isin(nb_pixels, gindex_8nb[spikes[0,:], :]).any(axis=1) for spikes in spikes_sublist])\n",
    "    select_pixels = mask_w_arr.any(axis=0)\n",
    "    coords_w = spikes_w[0, select_pixels] \n",
    "    w_tables = cp_insert(mask_w_arr[:, select_pixels], cp.ones([1, len(select_pixels)]), idx, 0)\n",
    "    # Retrieve intensity values for the selected coordinates\n",
    "    intensities = spikes_w[1:, select_pixels]\n",
    "    arr_w = cp.concatenate([cp.expand_dim(coords_w, 0), intensities, w_tables], axis=0)\n",
    "    \n",
    "    return arr_w\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.environ['SPIKESDATA']\n",
    "spikes_db = pd.read_parquet(os.path.join(data_dir, 'spikes_df_2010.parquet'), engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes_db2 = spikes_db.set_index(['GroupNumber', 'Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Size</th>\n",
       "      <th>Wavelength</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GroupNumber</th>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>2010-05-13 00:00:02.090000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:02.09Z_0193.spikes...</td>\n",
       "      <td>106560</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-13 00:00:03.570000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:03.57Z_0094.spikes...</td>\n",
       "      <td>103680</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-13 00:00:05.070000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:05.07Z_0335.spikes...</td>\n",
       "      <td>126720</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-13 00:00:06.580000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:06.58Z_0171.spikes...</td>\n",
       "      <td>40320</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-13 00:00:08.080000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:08.08Z_0211.spikes...</td>\n",
       "      <td>60480</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                           Path  \\\n",
       "GroupNumber Time                                                                                  \n",
       "0           2010-05-13 00:00:02.090000+00:00  2010/05/13/2010-05-13T00:00:02.09Z_0193.spikes...   \n",
       "            2010-05-13 00:00:03.570000+00:00  2010/05/13/2010-05-13T00:00:03.57Z_0094.spikes...   \n",
       "            2010-05-13 00:00:05.070000+00:00  2010/05/13/2010-05-13T00:00:05.07Z_0335.spikes...   \n",
       "            2010-05-13 00:00:06.580000+00:00  2010/05/13/2010-05-13T00:00:06.58Z_0171.spikes...   \n",
       "            2010-05-13 00:00:08.080000+00:00  2010/05/13/2010-05-13T00:00:08.08Z_0211.spikes...   \n",
       "\n",
       "                                                Size  Wavelength  \n",
       "GroupNumber Time                                                  \n",
       "0           2010-05-13 00:00:02.090000+00:00  106560         193  \n",
       "            2010-05-13 00:00:03.570000+00:00  103680          94  \n",
       "            2010-05-13 00:00:05.070000+00:00  126720         335  \n",
       "            2010-05-13 00:00:06.580000+00:00   40320         171  \n",
       "            2010-05-13 00:00:08.080000+00:00   60480         211  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spikes_db2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the filepaths (typically 7) for a given group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16777216, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################################################################\n",
    "# Pre-compute the 8-connectivity lookup table. This will be shared across parallel workers.\n",
    "################################################################################################\n",
    "# List of relative 2D coordinates for 8-neighbour connectiviy (9-element list). 1st one is the origin pixel.\n",
    "coords_8nb = np.array([[0, 0], [-1, 0], [-1, -1], [0, -1], [1, -1], [1, 0], [1, 1], [0, 1], [-1, 1]])\n",
    "# Array of 2D coordinates for a 4096 x 4096 array. Matrix convention is kept. [rows, cols] = [y-axis, x-axis]\n",
    "ny, nx = [4096, 4096]\n",
    "coords_1d = np.arange(nx * ny)\n",
    "coordy, coordx = np.unravel_index(coords_1d, [ny, nx]) # also possible by raveling a meshgrid() output\n",
    "coords2d = np.array([coordy, coordx])\n",
    "# Create the array of 2D coordinates of 8-neighbours associated with each pixel.\n",
    "# pixel 0 has 8 neighbour + itself, pixel 1 has 8 neighbour + itself, etc...\n",
    "coords2d_8nb = coords2d[np.newaxis, ...] + coords_8nb[..., np.newaxis]\n",
    "# Handle off-edges coordinates by clipping to the edges, operation done in-place. Here, square detector assumed. Update\n",
    "# to per-axis clipping if that ever changes for another instrument.\n",
    "np.clip(coords2d_8nb, 0, nx-1, out=coords2d_8nb)\n",
    "# Convert to 1D coordinates.\n",
    "index_8nb = np.array([coords2d_8nb[i, 0, :] * nx + coords2d_8nb[i, 1, :] for i in range(len(coords_8nb))],\n",
    "                     dtype='int32', order='C').T\n",
    "index_8nb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 8486)\n",
      "(3, 30356)\n",
      "(3, 36549)\n",
      "(3, 7993)\n",
      "(3, 13781)\n",
      "(3, 26443)\n",
      "(3, 27576)\n"
     ]
    }
   ],
   "source": [
    "n_co_spikes = 2\n",
    "\n",
    "group_n = 0\n",
    "fpaths = spikes_db2.loc[group_n]['Path'].values\n",
    "spikes_list = [fitsio.read(os.path.join(data_dir, f)) for f in fpaths]\n",
    "for spikes in spikes_list:\n",
    "    print(spikes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['coords' , 'int1', 'int2', 'w1', 'w2', 'w3', 'w4', 'w5', 'w6', 'w7']\n",
    "#column_names_list = [[names for names in column_names[:i]+column_names[i+1:]] for i in range(7)]\n",
    "\n",
    "df = pd.DataFrame(columns=column_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes_pix = [[spikes[0,:] for spikes in spikes_list[:i]+spikes_list[i+1:]] for i in range(7)]\n",
    "pixels_ws = [spikes_list[i][0,:] for i in range(7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "group_data = np.concatenate([extract_coincidentals(spikes_list, i) for i in range(7)], axis=1)\n",
    "u, idx = np.unique(group_data[0, :], return_index=True)\n",
    "group_data2 = group_data[:, idx]\n",
    "df = pd.DataFrame(group_data2.T, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "# Spikes coordinates at given wavelength index\n",
    "spikes_w = spikes_list[idx]\n",
    "# Associated neighbour coordinates\n",
    "nb_pixels = index_8nb[spikes_w[0, :], :]\n",
    "# Sublist of spikes data that will excludes the one serving as template\n",
    "spikes_sublist = spikes_list[:idx]+spikes_list[idx+1:]\n",
    "# Coincidental cross-referencing. \n",
    "a = index_8nb[spikes_sublist[0][0,:], :]\n",
    "#mask_w_arr = np.array([np.isin(nb_pixels, index_8nb[spikes[0,:], :]).any(axis=1) for spikes in spikes_sublist])\n",
    "m = np.isin(nb_pixels, index_8nb[spikes_sublist[0][0,:], :])\n",
    "print(nb_pixels.shape)\n",
    "print(index_8nb[spikes_sublist[0][0,:], :].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit nb_pixels = index_8nb[spikes_w[0, :], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test GPU version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(index_8nb.dtype)\n",
    "tempdf = pd.DataFrame(index_8nb)\n",
    "tempdf.head()\n",
    "print(index_8nb.nbytes/(1024**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf8nb = cudf.from_pandas(tempdf)\n",
    "gdf8nb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "# Spikes coordinates at given wavelength index\n",
    "coords = spikes_list[idx][0]\n",
    "s1 = cudf.Series(coords)\n",
    "print(s1.head())\n",
    "\n",
    "# Associated neighbour coordinates\n",
    "# nb_pixels = gindex_8nb[spikes_w[0, :], :]\n",
    "# # Sublist of spikes data that will excludes the one serving as template\n",
    "# spikes_sublist = spikes_glist[:idx]+spikes_glist[idx+1:]\n",
    "# print(nb_pixels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit a = gdf8nb.loc[coords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = gdf8nb.loc[s1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del gdf8nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coincidental cross-referencing. \n",
    "# mask_w_arr = cp.array([cp.isin(nb_pixels, gindex_8nb[spikes[0,:], :]).any(axis=1) for spikes in spikes_sublist])\n",
    "\n",
    "a = np.random.randint(1, high=4096*4096, size=750000)\n",
    "b = np.random.randint(1, high=4096*4096, size=273204)\n",
    "c = np.isin(a, b)\n",
    "\n",
    "g1 = cp.random.randint(1, high=4096*4096, size=75000)\n",
    "g2 = cp.random.randint(1, high=4096*4096, size=300000)\n",
    "g3 = cp.in1d(g1, g2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "select_pixels = mask_w_arr.any(axis=0)\n",
    "coords_w = spikes_w[0, select_pixels] \n",
    "w_tables = cp_insert(mask_w_arr[:, select_pixels], cp.ones([1, len(select_pixels)]), idx, 0)\n",
    "# Retrieve intensity values for the selected coordinates\n",
    "intensities = spikes_w[1:, select_pixels]\n",
    "arr_w = cp.concatenate([cp.expand_dim(coords_w, 0), intensities, w_tables], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga = cp.arange(10)\n",
    "ga2 = cp.expand_dims(ga, 0)\n",
    "print(ga.shape)\n",
    "print(ga2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test storage format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydir = '/home/rattie/Data/AIA_Spikes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitsio.write(mydir+'/data.fits', a_large)\n",
    "np.savetxt(mydir+'/data.csv', a_large, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf.to_parquet(mydir+'/data.parquet', engine='pyarrow', compression='None')\n",
    "mydf.to_parquet(mydir+'/data_compressed_snappy.parquet', engine='pyarrow', compression='snappy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitsf = mydir+'/sample_0193.spikes.fits'\n",
    "myfits = fitsio.read(fitsf)\n",
    "myfits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit fdf = pd.DataFrame(myfits.T, columns=['a', 'b', 'c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquetf = mydir+'/sample_0193.spikes.compressed_snappy.parquet'\n",
    "fdf.to_parquet(parquetf, engine='pyarrow', compression='snappy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "df = pq.read_pandas(parquetf).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
