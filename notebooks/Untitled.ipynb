{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fitsio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_array(arr):\n",
    "    # Reshape to 1D without hard copy\n",
    "    # arr_1d = arr.ravel()\n",
    "    # Make a count of only the existing numbers (faster than histogram)\n",
    "    u, c = np.unique(arr, return_counts=True)\n",
    "    # Keep only rows that have values unique between rows\n",
    "    b = np.isin(arr, u[c==1]).all(axis=1)\n",
    "    return arr[b, :]\n",
    "\n",
    "\n",
    "def count_intersect(widx, raw_spikes, coincidental_1d_coords, count_filter_idx, counts):\n",
    "    \"\"\" Provides the coincidental coordinates and their indices in the raw spike file and occurence count\n",
    "    within the group. The indices in the raw spike file are used to retrieve the intensity values (before/after)\n",
    "\n",
    "    :param raw_spikes: list of spikes for one wavelength\n",
    "    :param coincidental_1d_coords: list of 1D coordinates of coincidental spikes integrated for the whole group\n",
    "    :param count_filter_idx: list of indices of the coincidental spikes mapping to the original list of spikes coords.\n",
    "    :param counts: distribution of spikes coords\n",
    "    :return: Coincidental coordinates, index in spike file, number of occurences >=n_co_spikes\n",
    "    \"\"\"\n",
    "\n",
    "    file_coords, idx1, idx2 = np.intersect1d(raw_spikes[0, :], coincidental_1d_coords, return_indices=True)\n",
    "    # Get intensity values at the coincidental coordinates\n",
    "    int_before = raw_spikes[1, idx1]\n",
    "    int_after = raw_spikes[2, idx1]\n",
    "    # Retrieve how many coincidental hits we had within the 8 neighbours.\n",
    "    group_counts = counts[count_filter_idx[idx2]]\n",
    "    # Map of the wavelength index, instead of actual wavelength value as 7-element group is 12s-time-based, not wavelength-based\n",
    "    widx = [widx]*len(file_coords)\n",
    "    \n",
    "    return file_coords, idx1, group_counts, widx, int_before, int_after\n",
    "\n",
    "\n",
    "def breakdown_coincidentals(spikes_list, coincidental_1d_coords, count_filter_idx, counts):\n",
    "    \"\"\" Provides the coincidental coordinates and their indices in the raw spike file and occurence count\n",
    "    within the group. The indices in the raw spike file are used to retrieve the intensity values (before/after)\n",
    "\n",
    "    :param raw_spikes: list of spikes for one wavelength\n",
    "    :param coincidental_1d_coords: list of 1D coordinates of coincidental spikes integrated for the whole group\n",
    "    :param count_filter_idx: list of indices of the coincidental spikes mapping to the original list of spikes coords.\n",
    "    :param counts: distribution of spikes coords\n",
    "    :return: Coincidental coordinates, index in spike file, number of occurences >=n_co_spikes\n",
    "    \"\"\"\n",
    "    \n",
    "    data_dict = {'coords':[], 'int1': [], 'int2': [], 'counts': [], 'widx': []}\n",
    "    \n",
    "    for widx, raw_spikes in enumerate(spikes_list):\n",
    "        file_coords, idx1, idx2 = np.intersect1d(raw_spikes[0, :], coincidental_1d_coords, return_indices=True)\n",
    "        # Get intensity values at the coincidental coordinates\n",
    "        #data = [raw_spikes[1, idx1], raw_spikes[2, idx1], counts[count_filter_idx[idx2]], [widx]*len(file_coords)]\n",
    "        # Map of the wavelength index, instead of actual wavelength value as 7-element group is 12s-time-based, not wavelength-based\n",
    "        data_dict['coords'].extend(file_coords)\n",
    "        data_dict['int1'].extend(raw_spikes[1, idx1])\n",
    "        data_dict['int2'].extend(raw_spikes[2, idx1])\n",
    "        data_dict['counts'].extend(counts[count_filter_idx[idx2]])\n",
    "        data_dict['widx'].extend([widx]*len(file_coords))\n",
    "        \n",
    "    \n",
    "    return data_dict\n",
    "\n",
    "\n",
    "def extract_coincidentals(spikes_w, spikes_pix):\n",
    "    \n",
    "    nb_pixels = index_8nb[spikes_w[0, :], :]\n",
    "\n",
    "    mask_w_arr = np.array([np.isin(nb_pixels, index_8nb[pixels, :]).any(axis=1) for pixels in spikes_pix])\n",
    "    select_pixels = mask_w_arr.any(axis=0)\n",
    "    coords_w = spikes_w[0, select_pixels] \n",
    "    w_tables = np.insert(mask_w_arr[:, select_pixels], 0, True, axis=0)\n",
    "    # Retrieve intensity values for the selected coordinates\n",
    "    intensities = spikes_w[1:, select_pixels]\n",
    "    arr_w = np.concatenate([coords_w[np.newaxis,...], intensities, w_tables], axis=0)\n",
    "    \n",
    "    return arr_w\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.environ['SPIKESDATA']\n",
    "spikes_db = pd.read_parquet(os.path.join(data_dir, 'spikes_df_2010.parquet'), engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Size</th>\n",
       "      <th>Wavelength</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GroupNumber</th>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">0</th>\n",
       "      <th>2010-05-13 00:00:02.090000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:02.09Z_0193.spikes...</td>\n",
       "      <td>106560</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-13 00:00:03.570000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:03.57Z_0094.spikes...</td>\n",
       "      <td>103680</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-13 00:00:05.070000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:05.07Z_0335.spikes...</td>\n",
       "      <td>126720</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-13 00:00:06.580000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:06.58Z_0171.spikes...</td>\n",
       "      <td>40320</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-13 00:00:08.080000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:08.08Z_0211.spikes...</td>\n",
       "      <td>60480</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-13 00:00:09.580000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:09.58Z_0304.spikes...</td>\n",
       "      <td>106560</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-13 00:00:11.080000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:11.08Z_0131.spikes...</td>\n",
       "      <td>100800</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">1</th>\n",
       "      <th>2010-05-13 00:00:14.080000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:14.08Z_0193.spikes...</td>\n",
       "      <td>43200</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-13 00:00:15.580000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:15.58Z_0094.spikes...</td>\n",
       "      <td>100800</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-13 00:00:17.080000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:17.08Z_0335.spikes...</td>\n",
       "      <td>126720</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-13 00:00:18.580000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:18.58Z_0171.spikes...</td>\n",
       "      <td>40320</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-13 00:00:20.090000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:20.09Z_0211.spikes...</td>\n",
       "      <td>60480</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-13 00:00:21.580000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:21.58Z_0304.spikes...</td>\n",
       "      <td>106560</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-13 00:00:23.070000+00:00</th>\n",
       "      <td>2010/05/13/2010-05-13T00:00:23.07Z_0131.spikes...</td>\n",
       "      <td>100800</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                           Path  \\\n",
       "GroupNumber Time                                                                                  \n",
       "0           2010-05-13 00:00:02.090000+00:00  2010/05/13/2010-05-13T00:00:02.09Z_0193.spikes...   \n",
       "            2010-05-13 00:00:03.570000+00:00  2010/05/13/2010-05-13T00:00:03.57Z_0094.spikes...   \n",
       "            2010-05-13 00:00:05.070000+00:00  2010/05/13/2010-05-13T00:00:05.07Z_0335.spikes...   \n",
       "            2010-05-13 00:00:06.580000+00:00  2010/05/13/2010-05-13T00:00:06.58Z_0171.spikes...   \n",
       "            2010-05-13 00:00:08.080000+00:00  2010/05/13/2010-05-13T00:00:08.08Z_0211.spikes...   \n",
       "            2010-05-13 00:00:09.580000+00:00  2010/05/13/2010-05-13T00:00:09.58Z_0304.spikes...   \n",
       "            2010-05-13 00:00:11.080000+00:00  2010/05/13/2010-05-13T00:00:11.08Z_0131.spikes...   \n",
       "1           2010-05-13 00:00:14.080000+00:00  2010/05/13/2010-05-13T00:00:14.08Z_0193.spikes...   \n",
       "            2010-05-13 00:00:15.580000+00:00  2010/05/13/2010-05-13T00:00:15.58Z_0094.spikes...   \n",
       "            2010-05-13 00:00:17.080000+00:00  2010/05/13/2010-05-13T00:00:17.08Z_0335.spikes...   \n",
       "            2010-05-13 00:00:18.580000+00:00  2010/05/13/2010-05-13T00:00:18.58Z_0171.spikes...   \n",
       "            2010-05-13 00:00:20.090000+00:00  2010/05/13/2010-05-13T00:00:20.09Z_0211.spikes...   \n",
       "            2010-05-13 00:00:21.580000+00:00  2010/05/13/2010-05-13T00:00:21.58Z_0304.spikes...   \n",
       "            2010-05-13 00:00:23.070000+00:00  2010/05/13/2010-05-13T00:00:23.07Z_0131.spikes...   \n",
       "\n",
       "                                                Size  Wavelength  \n",
       "GroupNumber Time                                                  \n",
       "0           2010-05-13 00:00:02.090000+00:00  106560         193  \n",
       "            2010-05-13 00:00:03.570000+00:00  103680          94  \n",
       "            2010-05-13 00:00:05.070000+00:00  126720         335  \n",
       "            2010-05-13 00:00:06.580000+00:00   40320         171  \n",
       "            2010-05-13 00:00:08.080000+00:00   60480         211  \n",
       "            2010-05-13 00:00:09.580000+00:00  106560         304  \n",
       "            2010-05-13 00:00:11.080000+00:00  100800         131  \n",
       "1           2010-05-13 00:00:14.080000+00:00   43200         193  \n",
       "            2010-05-13 00:00:15.580000+00:00  100800          94  \n",
       "            2010-05-13 00:00:17.080000+00:00  126720         335  \n",
       "            2010-05-13 00:00:18.580000+00:00   40320         171  \n",
       "            2010-05-13 00:00:20.090000+00:00   60480         211  \n",
       "            2010-05-13 00:00:21.580000+00:00  106560         304  \n",
       "            2010-05-13 00:00:23.070000+00:00  100800         131  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spikes_db2 = spikes_db.set_index(['GroupNumber', 'Time'])\n",
    "spikes_db2.head(14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the filepaths (typically 7) for a given group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16777216, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################################################################\n",
    "# Pre-compute the 8-connectivity lookup table. This will be shared across parallel workers.\n",
    "################################################################################################\n",
    "# List of relative 2D coordinates for 8-neighbour connectiviy (9-element list). 1st one is the origin pixel.\n",
    "coords_8nb = np.array([[0, 0], [-1, 0], [-1, -1], [0, -1], [1, -1], [1, 0], [1, 1], [0, 1], [-1, 1]])\n",
    "# Array of 2D coordinates for a 4096 x 4096 array. Matrix convention is kept. [rows, cols] = [y-axis, x-axis]\n",
    "ny, nx = [4096, 4096]\n",
    "coords_1d = np.arange(nx * ny)\n",
    "coordy, coordx = np.unravel_index(coords_1d, [ny, nx]) # also possible by raveling a meshgrid() output\n",
    "coords2d = np.array([coordy, coordx])\n",
    "# Create the array of 2D coordinates of 8-neighbours associated with each pixel.\n",
    "# pixel 0 has 8 neighbour + itself, pixel 1 has 8 neighbour + itself, etc...\n",
    "coords2d_8nb = coords2d[np.newaxis, ...] + coords_8nb[..., np.newaxis]\n",
    "# Handle off-edges coordinates by clipping to the edges, operation done in-place. Here, square detector assumed. Update\n",
    "# to per-axis clipping if that ever changes for another instrument.\n",
    "np.clip(coords2d_8nb, 0, nx-1, out=coords2d_8nb)\n",
    "# Convert to 1D coordinates.\n",
    "index_8nb = np.array([coords2d_8nb[i, 0, :] * nx + coords2d_8nb[i, 1, :] for i in range(len(coords_8nb))],\n",
    "                     dtype='int32', order='C').T\n",
    "index_8nb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 8486)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_co_spikes = 2\n",
    "\n",
    "group_n = 0\n",
    "fpaths = spikes_db2.loc[group_n]['Path'].values\n",
    "spikes_list = [fitsio.read(os.path.join(data_dir, f)) for f in fpaths]\n",
    "print(len(spikes_list))\n",
    "spikes_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coords</th>\n",
       "      <th>int1</th>\n",
       "      <th>int2</th>\n",
       "      <th>w1</th>\n",
       "      <th>w2</th>\n",
       "      <th>w3</th>\n",
       "      <th>w4</th>\n",
       "      <th>w5</th>\n",
       "      <th>w6</th>\n",
       "      <th>w7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [coords, int1, int2, w1, w2, w3, w4, w5, w6, w7]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = ['coords' , 'int1', 'int2', 'w1', 'w2', 'w3', 'w4', 'w5', 'w6', 'w7']\n",
    "#column_names_list = [[names for names in column_names[:i]+column_names[i+1:]] for i in range(7)]\n",
    "\n",
    "df = pd.DataFrame(columns=column_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8486\n",
      "30356\n",
      "36549\n",
      "7993\n",
      "13781\n",
      "26443\n",
      "27576\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "151184"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spikes_pix = [[spikes[0,:] for spikes in spikes_list[:i]+spikes_list[i+1:]] for i in range(7)]\n",
    "pixels_ws = [spikes_list[i][0,:] for i in range(7)]\n",
    "for pixels in pixels_ws:\n",
    "    print(len(pixels))\n",
    "\n",
    "np.sum([len(pixels) for pixels in pixels_ws])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1117)\n",
      "(10, 3191)\n"
     ]
    }
   ],
   "source": [
    "# For 1st wavelength ~112 ms (%%timeit)\n",
    "w1_arr = extract_coincidentals(spikes_list[0], spikes_pix[0])\n",
    "w2_arr = extract_coincidentals(spikes_list[1], spikes_pix[1])\n",
    "print(w1_arr.shape)\n",
    "print(w2_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "778 ms ± 9.86 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "group_data = np.concatenate([extract_coincidentals(spikes_list[i], spikes_pix[i]) for i in range(7)], axis=1)\n",
    "u, idx = np.unique(group_data[0, :], return_index=True)\n",
    "group_data2 = group_data[:, idx]\n",
    "df = pd.DataFrame(group_data2.T, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "503 µs ± 1.98 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15745"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(group_data2.T, columns=column_names)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16339"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.drop_duplicates()\n",
    "len(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3191,)\n",
      "(7, 3191)\n",
      "(8, 3191)\n"
     ]
    }
   ],
   "source": [
    "# For 2nd wavelength\n",
    "\n",
    "nb_pixels_w2 = index_8nb[pixels_ws[1], :]\n",
    "\n",
    "masks_w2 = [np.isin(nb_pixels_w2, index_8nb[pixels, :]).any(axis=1) for pixels in spikes_pix[1]]\n",
    "mask_w2_arr = np.array(masks_w2)\n",
    "select_pixels = mask_w2_arr.any(axis=0)\n",
    "coords_w2 =pixels_ws[1][select_pixels] # Combine the mask to fetch everything in one go, using broadcasting??\n",
    "print(coords_w2.shape)\n",
    "w2tables = np.insert(mask_w2_arr[:, select_pixels], 1, True, axis=0)\n",
    "print(w2tables.shape)\n",
    "w2_arr = np.concatenate([coords_w2[np.newaxis,...], w2tables], axis=0)\n",
    "print(w2_arr.shape)\n",
    "           \n",
    "# # Retrieve intensity values for the selected coordinates\n",
    "# intensity1 = spikes_list[1][1,reduction_mask][select_pixels]\n",
    "# intensity2 = spikes_list[1][2,reduction_mask][select_pixels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 4308)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w12 = np.concatenate([w1_arr, w2_arr], axis=1)\n",
    "w12.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2966</td>\n",
       "      <td>5548</td>\n",
       "      <td>426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5166</td>\n",
       "      <td>34967</td>\n",
       "      <td>34272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1662</td>\n",
       "      <td>30568</td>\n",
       "      <td>24222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31830</td>\n",
       "      <td>30196</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32314</td>\n",
       "      <td>4995</td>\n",
       "      <td>9627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       a      b      c\n",
       "0   2966   5548    426\n",
       "1   5166  34967  34272\n",
       "2   1662  30568  24222\n",
       "3  31830  30196    184\n",
       "4  32314   4995   9627"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_large = np.random.randint(0, 50_000, (10_000, 3))\n",
    "mydf = pd.DataFrame(a_large, columns=['a', 'b', 'c'])\n",
    "mydf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydir = '/home/rattie/Data/AIA_Spikes'\n",
    "fitsio.write(mydir+'/data.fits', a_large)\n",
    "np.savetxt(mydir+'/data.csv', a_large, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf.to_parquet(mydir+'/data.parquet', engine='pyarrow', compression='None')\n",
    "mydf.to_parquet(mydir+'/data_compressed_snappy.parquet', engine='pyarrow', compression='snappy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 8486)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitsf = mydir+'/sample_0193.spikes.fits'\n",
    "myfits = fitsio.read(fitsf)\n",
    "myfits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203 µs ± 975 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit fdf = pd.DataFrame(myfits.T, columns=['a', 'b', 'c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquetf = mydir+'/sample_0193.spikes.compressed_snappy.parquet'\n",
    "fdf.to_parquet(parquetf, engine='pyarrow', compression='snappy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.57 ms ± 128 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "df = pq.read_pandas(parquetf).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294 µs ± 3.31 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "myfits = fitsio.read(fitsf)\n",
    "fdf = pd.DataFrame(myfits.T, columns=['a', 'b', 'c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204 µs ± 1.73 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit fdf = pd.DataFrame(myfits.T, columns=['a', 'b', 'c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "964 µs ± 3.54 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit gdf = cudf.DataFrame({'a':myfits[0,:], 'b': myfits[1,:], 'c':myfits[2,:]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "cufits = cp.asarray(myfits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
